{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon\n",
    "import gluoncv as gcv\n",
    "import argparse\n",
    "import sys\n",
    "from gluoncv.utils import viz\n",
    "from gluoncv.data import VOCDetection\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from gluoncv.data.transforms.presets.ssd import SSDDefaultTrainTransform, SSDDefaultValTransform\n",
    "from gluoncv.utils.metrics.voc_detection import VOC07MApMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/csiro-aos-object-detection'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/csiro-aos-object-detection/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class with VOC structure so roughy data plays nicely with Gluon\n",
    "class VOCLike(VOCDetection):\n",
    "    CLASSES = ['orange_roughy_edge', 'orange_roughy', 'sea_anemone', 'sea_urchin', 'oreo',\n",
    "               'whiptail', 'eel', 'shark', 'worm', 'misc_fish', 'mollusc', 'shrimp',\n",
    "               'sea_star']\n",
    "    #CLASSES = ['person','dog']\n",
    "    def __init__(self, root, splits, transform=None, index_map=None, preload_label=True):\n",
    "        super(VOCLike, self).__init__(root, splits, transform, index_map, preload_label)\n",
    "        \n",
    "# define the data loader\n",
    "def get_dataloader(net, val_dataset, data_shape, batch_size, num_workers, ctx):\n",
    "    \"\"\"Get dataloader.\"\"\"\n",
    "    width, height = data_shape, data_shape\n",
    "    \n",
    "    #val_batchify_fn = Tuple(Stack(), Stack(), Stack())  # stack image, cls_targets, box_targets\n",
    "    val_batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "    \n",
    "    # the validation loader \n",
    "    val_loader = gluon.data.DataLoader(\n",
    "        val_dataset.transform(SSDDefaultValTransform(width, height)),\n",
    "        batch_size, False, batchify_fn=val_batchify_fn, last_batch='keep',\n",
    "        num_workers=num_workers)\n",
    "    \n",
    "    return val_loader\n",
    "\n",
    "\n",
    "# define validation\n",
    "def validate(net, val_data, ctx, eval_metric):\n",
    "    \"\"\"\n",
    "    Test on validation dataset\n",
    "    :param net: network being used\n",
    "    :param val_data: validation dataset\n",
    "    :param ctx: training context (flag to set gpu)\n",
    "    :param eval_metric: metric to quote performance\n",
    "    :return eval_metric: updated evaluation metric \n",
    "    \"\"\"\n",
    "    eval_metric.reset()\n",
    "    # set nms threshold and topk constraint (what bounding boxes are legit)\n",
    "    net.set_nms(nms_thresh=0.45, nms_topk=400)\n",
    "    net.hybridize(static_alloc=True, static_shape=True)\n",
    "    \n",
    "    flag = 0\n",
    "    for batch in val_data:\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        det_bboxes = []\n",
    "        det_ids = []\n",
    "        det_scores = []\n",
    "        gt_bboxes = []\n",
    "        gt_ids = []\n",
    "        gt_difficults = []\n",
    "        for x, y in zip(data, label):\n",
    "            # get prediction results\n",
    "            ids, scores, bboxes = net(x)\n",
    "            det_ids.append(ids)\n",
    "            det_scores.append(scores)\n",
    "            # clip to image size\n",
    "            det_bboxes.append(bboxes.clip(0, batch[0].shape[2]))\n",
    "            # split ground truths\n",
    "            gt_ids.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
    "            gt_bboxes.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
    "            gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\n",
    "\n",
    "        # update metric\n",
    "        eval_metric.update(det_bboxes, det_ids, det_scores, gt_bboxes, gt_ids, gt_difficults)\n",
    "    return eval_metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_wghts = 'clf-outputs/102720-ssd_512_mobilenet1.0_voc_roughy_OP19_10.params'\n",
    "#net_wghts = 'clf-outputs/102720-ssd_512_mobilenet1.0_voc_roughy_OP16_10.params'\n",
    "net_wghts = 'clf-outputs/090320-ssd_512_mobilenet1.0_roughy.params'\n",
    "test_set = 'VOCport' \n",
    "test_run = 'OP12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "# find and activate GPU\n",
    "contx = [mx.gpu(0)]\n",
    "print('GPU found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the class names\n",
    "classes = ['orange_roughy_edge', 'orange_roughy', 'sea_anemone', 'sea_urchin', 'oreo', 'whiptail', 'eel', 'shark', 'worm', 'misc_fish', 'mollusc', 'shrimp', 'sea_star']\n",
    "\n",
    "net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_custom', classes=classes, pretrained_base=False)\n",
    "net.load_parameters(net_wghts)\n",
    "net.collect_params().reset_ctx(contx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "test_dataset = VOCLike(root=test_set, splits=((test_run, 'train'),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation metric (assume VOC07)\n",
    "val_metric = VOC07MApMetric(iou_thresh=0.5, class_names=test_dataset.classes)\n",
    "print(test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test data\n",
    "test_data = get_dataloader(net, test_dataset, 512, 16, 0, contx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the data\n",
    "map_name, mean_ap = validate(net, test_data, contx, val_metric)\n",
    "val_msg = '\\n'.join(['{}={}'.format(k, v) for k, v in zip(map_name, mean_ap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
